---
title: "EXe_3_OIN_dataset"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(rsample)
library(caret)
library(tidyverse)

```

```{r echo=FALSE, include=FALSE}
OIN_data <- read.csv("data/optical_interconnection_network.csv",dec = ",", sep = ";" )
#OIN_data = na.omit(OIN_data)
clean_OIN_data <- OIN_data[,c(1:10)]
head(clean_OIN_data)
set.seed(123)
OIN_data_split <- initial_split(clean_OIN_data, prop = .7)
OIN_data_train <- training(OIN_data_split)
OIN_data_test  <- testing(OIN_data_split)
```


# 1.Apply a MARS model with all features.
## How does the model performance compare to your previous models?
## How many of the features are influential? Which 10 features are considered most influential?
## Does your model include hinge functions? If so, explain their coefficient and plot their impact on the predicted response variable.
## Does your model include interactions? If so, pick the interaction effect that is most influential and explain the coefficient.

```{r echo=FALSE, include=FALSE}
library(earth)     # for fitting MARS models
# Fit a basic MARS model
mars1 <- earth(
  Channel.Utilization ~ .,  
  data = OIN_data_train   
)

# Print model summary
print(mars1)
```

```{r}
plot(mars1, which = 1)
```


```{r}
hyper_grid <- expand.grid(
  nprune = seq(2, 50, length.out = 10) %>% floor(),
  degree = 1:3
)

# perform resampling
set.seed(123)
cv_mars <- train(
  Channel.Utilization ~ ., 
  data = OIN_data_train, 
  trControl = trainControl(method = "cv", number = 10),
  method = "earth", #<<
  tuneGrid = hyper_grid,
  metric = "RMSE"
  )

# best model
cv_mars$results %>%
  filter(
    nprune == cv_mars$bestTune$nprune,
    degree == cv_mars$bestTune$degree
    )
```

```{r}
plot(cv_mars)
```

```{r}
library(vip)       # for variable importance
p1 <- vip(cv_mars, num_features = 10, geom = "point", value = "gcv") + ggtitle("GCV")
p2 <- vip(cv_mars, num_features = 10, geom = "point", value = "rss") + ggtitle("RSS")
gridExtra::grid.arrange(p1, p2, ncol = 2)
```


# 2.Apply a random forest model.
## First, apply a default random forest model.
```{r }
library(ranger) Client-Server
features <- length(setdiff(names(OIN_data_train), "Channel.Utilization"))

# perform basic random forest model
rf1 <- ranger(
  formula    = Channel.Utilization ~ ., 
  data       = OIN_data_train, 
  num.trees  = length(features) * 10,
  mtry       = floor(features / 3),
  respect.unordered.factors = 'order',
  verbose    = FALSE,
  seed       = 123
  )


# get OOB RMSE
(default_rmse <- sqrt(rf1$prediction.error))

```

## Now apply a a full cartesian grid search across various values of mtry, tree complexity & sampling scheme.
```{r}
# create hyperparameter grid
hyper_grid <- expand.grid(
  mtry = floor(features * c(.05, .15, .25, .333, .4)),
  min.node.size = c(1, 3, 5, 10), 
  replace = c(TRUE, FALSE),                               
  sample.fraction = c(.5, .63, .8),                       
  rmse = NA                                               
)
# cartesian grid 
for(i in seq_len(nrow(hyper_grid))) {
fit <- ranger(
    formula         = Channel.Utilization ~ ., 
    data            = OIN_data_train, 
    num.trees       = features * 10,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$min.node.size[i],
    replace         = hyper_grid$replace[i],
    sample.fraction = hyper_grid$sample.fraction[i],
    verbose         = FALSE,
    seed            = 123,
    respect.unordered.factors = 'order',
  )
 hyper_grid$rmse[i] <- sqrt(fit$prediction.error)
}

hyper_grid %>%
  arrange(rmse) %>%
  mutate(perc_gain = (default_rmse - rmse) / default_rmse * 100) %>%
  head(10)
```

## Now run a random grid search across the same hyperparameter grid but restrict the time or number of models to run to 50% of the models ran in the full cartesian.

# 3. Pick the best performing model from above.
## Identify the most influential features for this model.
## Plot the top 10 most influential features.
## Do these features have positive or negative impacts on your response variable?
```{r}
p1 <- vip(cv_mars, num_features = 40, geom = "point", value = "gcv") + ggtitle("GCV")
p2 <- vip(cv_mars, num_features = 40, geom = "point", value = "rss") + ggtitle("RSS")
gridExtra::grid.arrange(p1, p2, ncol = 2)
```

## Create partial dependence plots for these features. Explain the relationship between the feature and the predicted values.

```{r pdp, fig.width=15, fig.height=3, warning=FALSE, message=FALSE}
library(pdp)       # for variable relationships
library(vip)       # for variable importance
# Construct partial dependence plots
p1 <- partial(cv_mars, pred.var = "Input.Waiting.Time", grid.resolution = 10) %>% 
  ggplot(aes(Input.Waiting.Time, yhat)) +
  geom_line()


p2 <- partial(cv_mars, pred.var = "Network.Response.Time", grid.resolution = 10) %>% 
  ggplot(aes(Network.Response.Time, yhat)) +
  geom_line()


p3 <- partial(cv_mars, pred.var = c("Input.Waiting.Time", "Network.Response.Time"), 
              grid.resolution = 10) %>% 
  plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, colorkey = TRUE, 
              screen = list(z = -20, x = -60))
# Display plots side by side
gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
```



